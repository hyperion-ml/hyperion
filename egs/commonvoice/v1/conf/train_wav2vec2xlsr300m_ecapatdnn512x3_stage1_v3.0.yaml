data:
  train:
    dataset:
      wav_scale: 1
      aug_cfgs: 
        - conf/reverb_noise_aug.yaml
      return_segment_info:
        - language
    sampler:
      sampler_type: 'class_weighted_random_seg_chunk_sampler'
      min_batch_size: 64
      max_chunk_length: 2.0
      min_chunk_length: 2.0
      drop_last: false
      # weighted
      weight_mode: "data-prior"
      class_name: "language"
      weight_exponent: 0.3
      num_chunks_per_seg_epoch: 0.1


    data_loader:
      num_workers: 8
  val:
    dataset:
      aug_cfgs: 
        - conf/reverb_noise_aug.yaml
      wav_scale: 1
      return_segment_info:
        - language
    sampler:
      sampler_type: 'class_weighted_random_seg_chunk_sampler'
      min_batch_size: 64
      max_chunk_length: 2.0
      min_chunk_length: 2.0
      drop_last: false
      # weighted
      weight_mode: "data-prior"
      class_name: "language"
      weight_exponent: 0.3
      num_chunks_per_seg_epoch: 0.3
    data_loader:
      num_workers: 8
model: wav2vec2xlsr300m_ecapatdnn512x3_do0.2.yaml
trainer:
  optim:
    opt_type: sgd
    lr: 0.003
    momentum: 0.9
    weight_decay: 4e-4
  lrsched:
    lrsch_type: exp_lr
    decay_rate: 0.5
    decay_steps: 30000
    hold_steps: 16000
    min_lr: 4e-5
    warmup_steps: 3000
    update_lr_on_opt_step: true
  grad_clip: 100
  use_amp: true
  log_interval: 1000
  epochs: 120
  # eff_batch_size: 1024
  eff_batch_size: 128
  train_mode: hf-feats-frozen-nograd

 
