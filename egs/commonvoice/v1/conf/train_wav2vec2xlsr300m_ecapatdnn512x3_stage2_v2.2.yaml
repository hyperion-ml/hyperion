data:
  train:
    dataset:
      wav_scale: 1
      aug_cfgs: 
        - conf/reverb_noise_aug.yaml
      return_segment_info:
        - language
    sampler:
      #sampler_type: 'bucketing_seg_sampler'
      sampler_type: 'class_weighted_random_bucketing_seg_sampler'
      max_batch_length: 50.
      max_audio_length: 20.
      min_batch_size: 1
      drop_last: false
      # for class_weighted_random_bucketing_seg_sampler
      base_sampler_type: class_weighted_seg_sampler
      weight_mode: "data-prior"
      class_name: "language"
      weight_exponent: 0.3
      num_chunks_per_seg_epoch: 0.3
    data_loader:
      num_workers: 1
  val:
    dataset:
      aug_cfgs: 
        - conf/reverb_noise_aug.yaml
      wav_scale: 1
      return_segment_info:
        - language
    sampler:
      #sampler_type: 'bucketing_seg_sampler'
      sampler_type: 'class_weighted_random_bucketing_seg_sampler'
      max_batch_length: 50.
      max_audio_length: 20.
      min_batch_size: 1
      drop_last: true
      # for class_weighted_random_bucketing_seg_sampler
      base_sampler_type: class_weighted_seg_sampler
      weight_mode: "data-prior"
      class_name: "language"
      weight_exponent: 0.3
      num_chunks_per_seg_epoch: 1.0
    data_loader:
      num_workers: 1
model:
  languageid:
    cos_scale: 32.0
trainer:
  optim:
    opt_type: sgd
    lr: 0.0001
    momentum: 0.9
    weight_decay: 4e-4
  lrsched:
    lrsch_type: exp_lr
    decay_rate: 0.5
    decay_steps: 60000
    hold_steps: 30000
    min_lr: 4e-5
    warmup_steps: 5000
    update_lr_on_opt_step: true
  grad_clip: 100
  use_amp: true
  log_interval: 1000
  epochs: 120
  # eff_batch_size: 1024
  eff_batch_size: 128
  train_mode: full

 
