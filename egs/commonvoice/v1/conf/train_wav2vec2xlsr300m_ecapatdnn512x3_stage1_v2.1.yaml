data:
  train:
    dataset:
      wav_scale: 1
      aug_cfgs: 
        - conf/reverb_noise_aug.yaml
      return_segment_info:
        - language
    sampler:
      #sampler_type: 'bucketing_seg_sampler'
      sampler_type: 'class_weighted_random_bucketing_seg_sampler'
      max_batch_length: 85.
      min_batch_size: 2
      drop_last: false
      # for class_weighted_random_bucketing_seg_sampler
      base_sampler_type: class_weighted_seg_sampler
      weight_mode: "data-prior"
      class_name: "language"
      weight_exponent: 0.3
      num_chunks_per_seg_epoch: 1.0


    data_loader:
      num_workers: 4
  val:
    dataset:
      aug_cfgs: 
        - conf/reverb_noise_aug.yaml
      wav_scale: 1
      return_segment_info:
        - language
    sampler:
      #sampler_type: 'bucketing_seg_sampler'
      sampler_type: 'class_weighted_random_bucketing_seg_sampler'
      max_batch_length: 30
      min_batch_size: 2
      drop_last: true
      # for class_weighted_random_bucketing_seg_sampler
      base_sampler_type: class_weighted_seg_sampler
      weight_mode: "data-prior"
      class_name: "language"
      weight_exponent: 0.3
      num_chunks_per_seg_epoch: 1.0
    data_loader:
      num_workers: 4
model: wav2vec2xlsr300m_ecapatdnn512x3_do0.2.yaml
trainer:
  optim:
    opt_type: sgd
    lr: 0.003
    momentum: 0.9
    weight_decay: 4e-4
  lrsched:
    lrsch_type: exp_lr
    decay_rate: 0.5
    decay_steps: 4200
    hold_steps: 1500
    min_lr: 4e-5
    warmup_steps: 1500
    update_lr_on_opt_step: true
  grad_clip: 100
  use_amp: true
  log_interval: 1000
  epochs: 120
  # eff_batch_size: 1024
  eff_batch_size: 128
  train_mode: hf-feats-frozen-nograd

 
